{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install deap\n",
        "!pip3 install pyswarms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7pHuSXGaqoc",
        "outputId": "ae58772b-4c9e-4c47-9971-17f3fe8a5d0b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deap in /usr/local/lib/python3.9/dist-packages (1.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from deap) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyswarms in /usr/local/lib/python3.9/dist-packages (1.3.0)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from pyswarms) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pyswarms) (1.22.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from pyswarms) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from pyswarms) (4.65.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from pyswarms) (6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from pyswarms) (1.10.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from pyswarms) (22.2.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3.1->pyswarms) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3.1->pyswarms) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3.1->pyswarms) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.11.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=1.3.1->pyswarms) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "cznWD8QTY4z-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from deap import base, creator, tools, algorithms\n",
        "from pyswarms.single import GlobalBestPSO\n",
        "from secrets import randbelow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Bank_Personal_Loan_Modelling.csv\")\n",
        "\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5IEwHscZFE7",
        "outputId": "28027bd8-49a9-49f7-c63c-4bc84ad1a09c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 14 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   ID                  5000 non-null   int64  \n",
            " 1   Age                 5000 non-null   int64  \n",
            " 2   Experience          5000 non-null   int64  \n",
            " 3   Income              5000 non-null   int64  \n",
            " 4   ZIP Code            5000 non-null   int64  \n",
            " 5   Family              5000 non-null   int64  \n",
            " 6   CCAvg               5000 non-null   float64\n",
            " 7   Education           5000 non-null   int64  \n",
            " 8   Mortgage            5000 non-null   int64  \n",
            " 9   Personal Loan       5000 non-null   int64  \n",
            " 10  Securities Account  5000 non-null   int64  \n",
            " 11  CD Account          5000 non-null   int64  \n",
            " 12  Online              5000 non-null   int64  \n",
            " 13  CreditCard          5000 non-null   int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 547.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['ZIP Code','ID'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "rcEOwbpbYD1L"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = data.drop('Personal Loan',axis=1)\n",
        "y = data['Personal Loan']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "i9WEfpmUZTR6"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data))\n",
        "print(\"No. of columns : \", 11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zqyouGDYYq6",
        "outputId": "cda196a9-0d47-4a65-db12-0500877657a6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000\n",
            "No. of columns :  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Neural Networks + Genetic Algorithms"
      ],
      "metadata": {
        "id": "nQFDL3kLekmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "'''\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def create_population(pop_size, input_size, hidden_size, output_size):\n",
        "    population = []\n",
        "    for i in range(pop_size):\n",
        "        net = NeuralNet(input_size, hidden_size, output_size)\n",
        "        for param in net.parameters():\n",
        "            param.data = torch.from_numpy(np.random.uniform(-1, 1, size=param.data.size())).float()\n",
        "        population.append(net)\n",
        "    return population\n",
        "\n",
        "\n",
        "def fitness_function(net, data, target):\n",
        "    inputs = torch.from_numpy(data).float()\n",
        "    targets = torch.from_numpy(target).float()\n",
        "    outputs = net(inputs)\n",
        "    loss = torch.nn.BCELoss()(outputs, targets)\n",
        "    acc = ((outputs > 0.5) == targets).sum().item() / len(outputs)\n",
        "    return acc, loss\n",
        "\n",
        "\n",
        "pop_size = 50\n",
        "num_generations = 50\n",
        "mutation_rate = 0.1\n",
        "input_size = 20\n",
        "hidden_size = 6\n",
        "output_size = 1\n",
        "data = np.random.rand(981, 20)\n",
        "target = np.random.randint(2, size=(981, 1))\n",
        "\n",
        "\n",
        "population = create_population(pop_size, input_size, hidden_size, output_size)\n",
        "\n",
        "for generation in range(num_generations):\n",
        "    fitness_scores = []\n",
        "    for i in range(pop_size):\n",
        "        net = population[i]\n",
        "        acc, loss = fitness_function(net, data, target)\n",
        "        fitness_scores.append((i, acc))\n",
        "\n",
        "    fitness_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    best_individual = population[fitness_scores[0][0]]\n",
        "    best_acc, best_loss = fitness_function(best_individual, data, target)\n",
        "    print(\"Generation:\", generation, \"Best accuracy:\", best_acc)\n",
        "\n",
        "    parents = [population[i] for i in range(pop_size//2)]\n",
        "\n",
        "    offspring = []\n",
        "    for i in range(pop_size//2):\n",
        "        parent1 = parents[np.random.randint(len(parents))]\n",
        "        parent2 = parents[np.random.randint(len(parents))]\n",
        "        child = NeuralNet(input_size, hidden_size, output_size)\n",
        "        for c, p1, p2 in zip(child.parameters(), parent1.parameters(), parent2.parameters()):\n",
        "            c.data = torch.where(torch.rand_like(c.data) > 0.5, p1.data, p2.data)\n",
        "        offspring.append(child)\n",
        "\n",
        "    for i in range(len(offspring)):\n",
        "        child = offspring[i]\n",
        "        for param in child.parameters():\n",
        "            if np.random.rand() < mutation_rate:\n",
        "                param.data += torch.from_numpy(np.random.normal(scale=0.1, size=param.data.size())).float()\n",
        "\n",
        "    for i in range(pop_size//2):\n",
        "        population[-(i+1)] = offspring[i]\n",
        "\n",
        "\n",
        "    fitness_scores = []\n",
        "    for i in range(pop_size):\n",
        "      net = population[i]\n",
        "      acc, loss = fitness_function(net, data, target)\n",
        "      fitness_scores.append((i, acc))\n",
        "\n",
        "\n",
        "    fitness_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "\n",
        "best_individual = population[fitness_scores[0][0]]\n",
        "best_acc, best_loss = fitness_function(best_individual, data, target)\n",
        "print(\"Best accuracy:\", best_acc)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz_SQPXpZ1Rr",
        "outputId": "7fd58f18-c0d4-4a14-f474-8f16241c4b6d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation: 0 Best accuracy: 0.5219164118246687\n",
            "Generation: 1 Best accuracy: 0.5219164118246687\n",
            "Generation: 2 Best accuracy: 0.5300713557594292\n",
            "Generation: 3 Best accuracy: 0.528032619775739\n",
            "Generation: 4 Best accuracy: 0.5341488277268094\n",
            "Generation: 5 Best accuracy: 0.5219164118246687\n",
            "Generation: 6 Best accuracy: 0.5361875637104995\n",
            "Generation: 7 Best accuracy: 0.5219164118246687\n",
            "Generation: 8 Best accuracy: 0.5219164118246687\n",
            "Generation: 9 Best accuracy: 0.5219164118246687\n",
            "Generation: 10 Best accuracy: 0.5219164118246687\n",
            "Generation: 11 Best accuracy: 0.5219164118246687\n",
            "Generation: 12 Best accuracy: 0.5219164118246687\n",
            "Generation: 13 Best accuracy: 0.5219164118246687\n",
            "Generation: 14 Best accuracy: 0.5310907237512742\n",
            "Generation: 15 Best accuracy: 0.5219164118246687\n",
            "Generation: 16 Best accuracy: 0.5219164118246687\n",
            "Generation: 17 Best accuracy: 0.5219164118246687\n",
            "Generation: 18 Best accuracy: 0.5361875637104995\n",
            "Generation: 19 Best accuracy: 0.5249745158002038\n",
            "Generation: 20 Best accuracy: 0.528032619775739\n",
            "Generation: 21 Best accuracy: 0.5219164118246687\n",
            "Generation: 22 Best accuracy: 0.5249745158002038\n",
            "Generation: 23 Best accuracy: 0.5219164118246687\n",
            "Generation: 24 Best accuracy: 0.5219164118246687\n",
            "Generation: 25 Best accuracy: 0.5249745158002038\n",
            "Generation: 26 Best accuracy: 0.5219164118246687\n",
            "Generation: 27 Best accuracy: 0.5219164118246687\n",
            "Generation: 28 Best accuracy: 0.5310907237512742\n",
            "Generation: 29 Best accuracy: 0.527013251783894\n",
            "Generation: 30 Best accuracy: 0.5331294597349643\n",
            "Generation: 31 Best accuracy: 0.5219164118246687\n",
            "Generation: 32 Best accuracy: 0.5219164118246687\n",
            "Generation: 33 Best accuracy: 0.5219164118246687\n",
            "Generation: 34 Best accuracy: 0.5229357798165137\n",
            "Generation: 35 Best accuracy: 0.5219164118246687\n",
            "Generation: 36 Best accuracy: 0.5219164118246687\n",
            "Generation: 37 Best accuracy: 0.5219164118246687\n",
            "Generation: 38 Best accuracy: 0.5219164118246687\n",
            "Generation: 39 Best accuracy: 0.527013251783894\n",
            "Generation: 40 Best accuracy: 0.5219164118246687\n",
            "Generation: 41 Best accuracy: 0.5219164118246687\n",
            "Generation: 42 Best accuracy: 0.5229357798165137\n",
            "Generation: 43 Best accuracy: 0.5219164118246687\n",
            "Generation: 44 Best accuracy: 0.5219164118246687\n",
            "Generation: 45 Best accuracy: 0.5249745158002038\n",
            "Generation: 46 Best accuracy: 0.5219164118246687\n",
            "Generation: 47 Best accuracy: 0.5310907237512742\n",
            "Generation: 48 Best accuracy: 0.5219164118246687\n",
            "Generation: 49 Best accuracy: 0.5219164118246687\n",
            "Best accuracy: 0.528032619775739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Particle Swarm Optimization (PySwarms Module)"
      ],
      "metadata": {
        "id": "d82lqZJZP8gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "input_size = 20\n",
        "hidden_size = 10\n",
        "output_size = 1\n",
        "\n",
        "net = NeuralNet(input_size, hidden_size, output_size)\n",
        "\n",
        "# params = list(net.parameters())\n",
        "# print(params)\n",
        "# print(params[0].size())\n",
        "\n",
        "# Get the list of weights\n",
        "weights = []\n",
        "for name, param in net.named_parameters():\n",
        "    if 'weight' in name:\n",
        "        weights.append(param.data.tolist())\n",
        "\n",
        "\n",
        "\n",
        "print(len(weights))\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "for i in weights :\n",
        "  print(len(i))\n",
        "\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "for i in weights :\n",
        "  for j in i :\n",
        "    print(len(j))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B22QAU0hP8PM",
        "outputId": "ac7b83a6-d46f-4d29-ea16-0ea9f600bdce"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "\n",
            "\n",
            "\n",
            "10\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "20\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "input_size = 20\n",
        "hidden_size = 10\n",
        "output_size = 1\n",
        "\n",
        "net = NeuralNet(input_size, hidden_size, output_size)\n",
        "\n",
        "def fitness_function(weights):\n",
        "    with torch.no_grad():\n",
        "        # weights = weights.reshape(hidden_size * hidden_size, input_size+1)\n",
        "        weights = torch.Tensor(weights)\n",
        "\n",
        "        net.fc1.weight.data = weights[:, :input_size]\n",
        "        net.fc1.bias.data = weights[:, input_size]\n",
        "\n",
        "        net.fc2.weight.data = torch.Tensor(np.random.rand(1, hidden_size))\n",
        "        net.fc2.bias.data = torch.Tensor(np.random.rand(1))\n",
        "\n",
        "        x_test = torch.Tensor(np.random.rand(1, input_size))\n",
        "        y_pred = net(x_test)\n",
        "        loss = torch.nn.MSELoss()(y_pred, torch.Tensor([[1.0]]))\n",
        "        \n",
        "    return loss.item()\n",
        "\n",
        "bounds = (np.zeros(hidden_size*(input_size+1)), np.ones(hidden_size*(input_size+1)))\n",
        "\n",
        "options = {\"c1\":0.5, \"c2\":0.3, \"w\":0.9}\n",
        "optimizer = GlobalBestPSO(n_particles=10, dimensions=hidden_size*(input_size+1), options=options)\n",
        "best_weights, best_fitness = optimizer.optimize(fitness_function, iters=100)\n",
        "\n",
        "print(\"Best weights:\", best_weights)\n",
        "print(\"Best fitness:\", best_fitness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pXN-O6Xi_UP",
        "outputId": "7d8ce949-a925-4db1-92a3-a6320a9b3294"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-04-05 03:59:20,810 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
            "pyswarms.single.global_best: 100%|██████████|100/100, best_cost=0\n",
            "2023-04-05 03:59:21,318 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0, best pos: [5.36200693e-01 5.31850479e-01 5.71121321e-01 4.58514063e-01\n",
            " 2.89105332e-01 2.69881428e-01 4.14517147e-01 4.68812648e-01\n",
            " 7.17999175e-01 8.29097401e-01 9.56662281e-01 5.01001212e-01\n",
            " 1.52131062e-01 4.86674010e-01 5.50475221e-01 7.84799654e-01\n",
            " 7.02079961e-01 8.05328168e-01 1.88704879e-01 9.72985530e-01\n",
            " 5.22437727e-01 3.66472972e-01 4.10575922e-01 1.36487687e-02\n",
            " 7.65556391e-01 2.00115949e-01 3.56339637e-01 3.13531681e-01\n",
            " 4.15291273e-01 6.71767330e-01 7.70523337e-01 3.72879320e-01\n",
            " 6.85258651e-01 5.97205926e-01 8.31775710e-01 4.23683551e-01\n",
            " 7.22733349e-01 8.35692044e-02 2.30596330e-01 2.41426880e-01\n",
            " 5.43136613e-01 4.44868536e-01 5.28540519e-01 2.77622762e-01\n",
            " 1.50708046e-01 7.28094073e-01 9.61917347e-03 7.96781275e-01\n",
            " 5.76642519e-01 1.61455771e-01 8.99514828e-01 2.07745051e-01\n",
            " 2.72074972e-02 2.17556087e-01 7.50652298e-01 5.50742758e-01\n",
            " 7.44551334e-02 6.29450756e-01 8.24222150e-01 3.58440855e-01\n",
            " 8.75754653e-01 5.54061560e-01 3.12656268e-01 3.57710088e-01\n",
            " 9.22174447e-01 9.27131620e-01 8.11017978e-01 7.57158004e-01\n",
            " 9.20971807e-01 1.63058784e-01 7.24198766e-01 6.42016624e-01\n",
            " 3.20387139e-01 4.75561444e-01 3.63873162e-01 4.49106803e-01\n",
            " 1.57726070e-01 5.13011259e-01 6.11435513e-01 2.15664736e-01\n",
            " 8.21303919e-01 4.13742824e-02 8.03242129e-01 3.96600527e-01\n",
            " 7.11562054e-01 3.30589085e-01 2.81479472e-01 5.04200897e-01\n",
            " 3.99762027e-02 4.06380490e-01 9.07366165e-01 7.46299726e-01\n",
            " 3.48130430e-01 6.50656309e-01 2.42896238e-01 3.06352302e-02\n",
            " 1.46199906e-01 1.17680016e-01 2.69745969e-01 4.67086540e-01\n",
            " 5.52044339e-01 5.87407101e-01 1.37359061e-01 6.35307052e-03\n",
            " 5.90960720e-04 6.05108009e-01 3.24925278e-01 3.92660410e-02\n",
            " 1.09717633e-01 9.42800696e-01 5.73825837e-01 8.29148939e-01\n",
            " 3.88970649e-01 5.62920083e-01 2.19421721e-01 1.51872150e-01\n",
            " 3.28158032e-01 3.94045609e-01 3.83546518e-02 7.07953474e-01\n",
            " 2.51092667e-01 6.92115778e-01 5.60704525e-01 9.30124904e-01\n",
            " 2.36139806e-01 4.01337125e-01 7.91417682e-01 9.09431864e-01\n",
            " 8.89008538e-01 6.72452845e-01 7.90357397e-01 8.14286551e-01\n",
            " 3.59326802e-01 1.91190506e-01 6.38808810e-02 2.96020700e-01\n",
            " 2.80351080e-02 8.67744194e-01 1.90506436e-01 4.52156739e-01\n",
            " 3.24515991e-01 4.99238794e-01 8.42341172e-01 6.67765868e-01\n",
            " 8.90654460e-01 7.78479954e-01 2.73815950e-01 4.46464603e-01\n",
            " 8.45245021e-01 1.30573210e-01 9.22873498e-01 9.13023023e-01\n",
            " 6.20436742e-01 9.63097548e-01 4.88846775e-01 1.40024292e-01\n",
            " 5.95094148e-01 7.94601367e-01 9.72480638e-01 4.65977168e-01\n",
            " 6.84557509e-01 6.81979467e-01 4.69913144e-01 5.99305893e-01\n",
            " 9.15087001e-01 4.53962720e-01 6.41082323e-01 2.20073497e-02\n",
            " 6.98435501e-01 9.13095735e-01 2.33101559e-01 9.01788653e-01\n",
            " 3.94982208e-01 3.02737901e-01 9.24621827e-01 7.07325486e-01\n",
            " 8.00571950e-01 1.74914171e-01 9.48062846e-01 1.97857479e-01\n",
            " 9.47641758e-02 9.55618605e-01 3.52148377e-01 5.52183850e-02\n",
            " 9.96045833e-01 7.95389687e-02 3.13614142e-01 4.54053225e-01\n",
            " 5.00064073e-01 8.25831844e-01 8.53619807e-01 2.63475422e-01\n",
            " 1.46364158e-01 3.84414670e-01 3.79327802e-01 5.64089244e-01\n",
            " 3.59389276e-01 3.83596738e-01 7.02149917e-01 5.03539435e-01\n",
            " 4.29677232e-01 5.64119405e-01 1.68007553e-01 1.72331433e-01\n",
            " 7.87730586e-01 5.84045213e-01 5.02589255e-01 6.05572659e-01\n",
            " 1.44262826e-01 7.14910021e-01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weights: 0.0\n",
            "Best fitness: [5.36200693e-01 5.31850479e-01 5.71121321e-01 4.58514063e-01\n",
            " 2.89105332e-01 2.69881428e-01 4.14517147e-01 4.68812648e-01\n",
            " 7.17999175e-01 8.29097401e-01 9.56662281e-01 5.01001212e-01\n",
            " 1.52131062e-01 4.86674010e-01 5.50475221e-01 7.84799654e-01\n",
            " 7.02079961e-01 8.05328168e-01 1.88704879e-01 9.72985530e-01\n",
            " 5.22437727e-01 3.66472972e-01 4.10575922e-01 1.36487687e-02\n",
            " 7.65556391e-01 2.00115949e-01 3.56339637e-01 3.13531681e-01\n",
            " 4.15291273e-01 6.71767330e-01 7.70523337e-01 3.72879320e-01\n",
            " 6.85258651e-01 5.97205926e-01 8.31775710e-01 4.23683551e-01\n",
            " 7.22733349e-01 8.35692044e-02 2.30596330e-01 2.41426880e-01\n",
            " 5.43136613e-01 4.44868536e-01 5.28540519e-01 2.77622762e-01\n",
            " 1.50708046e-01 7.28094073e-01 9.61917347e-03 7.96781275e-01\n",
            " 5.76642519e-01 1.61455771e-01 8.99514828e-01 2.07745051e-01\n",
            " 2.72074972e-02 2.17556087e-01 7.50652298e-01 5.50742758e-01\n",
            " 7.44551334e-02 6.29450756e-01 8.24222150e-01 3.58440855e-01\n",
            " 8.75754653e-01 5.54061560e-01 3.12656268e-01 3.57710088e-01\n",
            " 9.22174447e-01 9.27131620e-01 8.11017978e-01 7.57158004e-01\n",
            " 9.20971807e-01 1.63058784e-01 7.24198766e-01 6.42016624e-01\n",
            " 3.20387139e-01 4.75561444e-01 3.63873162e-01 4.49106803e-01\n",
            " 1.57726070e-01 5.13011259e-01 6.11435513e-01 2.15664736e-01\n",
            " 8.21303919e-01 4.13742824e-02 8.03242129e-01 3.96600527e-01\n",
            " 7.11562054e-01 3.30589085e-01 2.81479472e-01 5.04200897e-01\n",
            " 3.99762027e-02 4.06380490e-01 9.07366165e-01 7.46299726e-01\n",
            " 3.48130430e-01 6.50656309e-01 2.42896238e-01 3.06352302e-02\n",
            " 1.46199906e-01 1.17680016e-01 2.69745969e-01 4.67086540e-01\n",
            " 5.52044339e-01 5.87407101e-01 1.37359061e-01 6.35307052e-03\n",
            " 5.90960720e-04 6.05108009e-01 3.24925278e-01 3.92660410e-02\n",
            " 1.09717633e-01 9.42800696e-01 5.73825837e-01 8.29148939e-01\n",
            " 3.88970649e-01 5.62920083e-01 2.19421721e-01 1.51872150e-01\n",
            " 3.28158032e-01 3.94045609e-01 3.83546518e-02 7.07953474e-01\n",
            " 2.51092667e-01 6.92115778e-01 5.60704525e-01 9.30124904e-01\n",
            " 2.36139806e-01 4.01337125e-01 7.91417682e-01 9.09431864e-01\n",
            " 8.89008538e-01 6.72452845e-01 7.90357397e-01 8.14286551e-01\n",
            " 3.59326802e-01 1.91190506e-01 6.38808810e-02 2.96020700e-01\n",
            " 2.80351080e-02 8.67744194e-01 1.90506436e-01 4.52156739e-01\n",
            " 3.24515991e-01 4.99238794e-01 8.42341172e-01 6.67765868e-01\n",
            " 8.90654460e-01 7.78479954e-01 2.73815950e-01 4.46464603e-01\n",
            " 8.45245021e-01 1.30573210e-01 9.22873498e-01 9.13023023e-01\n",
            " 6.20436742e-01 9.63097548e-01 4.88846775e-01 1.40024292e-01\n",
            " 5.95094148e-01 7.94601367e-01 9.72480638e-01 4.65977168e-01\n",
            " 6.84557509e-01 6.81979467e-01 4.69913144e-01 5.99305893e-01\n",
            " 9.15087001e-01 4.53962720e-01 6.41082323e-01 2.20073497e-02\n",
            " 6.98435501e-01 9.13095735e-01 2.33101559e-01 9.01788653e-01\n",
            " 3.94982208e-01 3.02737901e-01 9.24621827e-01 7.07325486e-01\n",
            " 8.00571950e-01 1.74914171e-01 9.48062846e-01 1.97857479e-01\n",
            " 9.47641758e-02 9.55618605e-01 3.52148377e-01 5.52183850e-02\n",
            " 9.96045833e-01 7.95389687e-02 3.13614142e-01 4.54053225e-01\n",
            " 5.00064073e-01 8.25831844e-01 8.53619807e-01 2.63475422e-01\n",
            " 1.46364158e-01 3.84414670e-01 3.79327802e-01 5.64089244e-01\n",
            " 3.59389276e-01 3.83596738e-01 7.02149917e-01 5.03539435e-01\n",
            " 4.29677232e-01 5.64119405e-01 1.68007553e-01 1.72331433e-01\n",
            " 7.87730586e-01 5.84045213e-01 5.02589255e-01 6.05572659e-01\n",
            " 1.44262826e-01 7.14910021e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ant Colony Optimization"
      ],
      "metadata": {
        "id": "ucADyOi6ZQET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "input_size = 20\n",
        "hidden_size = 10\n",
        "output_size = 1\n",
        "\n",
        "weights_1 = []\n",
        "for name, param in net.named_parameters():\n",
        "    if 'weight' in name:\n",
        "        weights_1.append(param.data.tolist())\n",
        "\n",
        "max_weight = 15\n",
        "\n",
        "values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20]\n",
        "# weights = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20]\n",
        "\n",
        "weights = []\n",
        "for _ in range(11):\n",
        "  weights.append(random.randint(1, max_weight))\n",
        "\n",
        "num_ants = 10\n",
        "evaporation_rate = 0.1\n",
        "alpha = 1.0\n",
        "beta = 2.0\n",
        "pheromone_init = 0.1\n",
        "\n",
        "\n",
        "num_items = len(values)\n",
        "pheromone = np.ones((num_items, max_weight+1)) * pheromone_init\n",
        "\n",
        "\n",
        "def fitness(solution):\n",
        "    sum = 0\n",
        "    lst = [weights[i]*solution[i] for i in range(num_items)]\n",
        "    for i in lst : \n",
        "      sum += i\n",
        "    total_weight = sum\n",
        "    if total_weight > max_weight:\n",
        "        return 0\n",
        "    \n",
        "    sum = 0\n",
        "    lst = [values[i]*solution[i] for i in range(num_items)]\n",
        "    for i in lst : \n",
        "      sum += i\n",
        "    total_weight = sum\n",
        "    return sum\n",
        "\n",
        "\n",
        "def item_selection(ant, remaining_weight):\n",
        "    item_scores = []\n",
        "    for i in range(num_items):\n",
        "        if ant['solution'][i] == 0 and weights[i] <= remaining_weight:\n",
        "            pheromone_score = pheromone[i][remaining_weight]\n",
        "            heuristic_score = values[i]/weights[i]\n",
        "            item_scores.append((i, pheromone_score**alpha * heuristic_score**beta))\n",
        "    if not item_scores:\n",
        "        return None\n",
        "    lst = [score for _, score in item_scores]\n",
        "    sum = 0\n",
        "    for i in lst :\n",
        "      sum += i\n",
        "    total_score = sum\n",
        "    probabilities = [(i, score/total_score) for i, score in item_scores]\n",
        "    selected_item = None\n",
        "    rand = random.random()\n",
        "    for i, prob in probabilities:\n",
        "        rand -= prob\n",
        "        if rand <= 0:\n",
        "            selected_item = i\n",
        "            break\n",
        "    return selected_item\n",
        "\n",
        "\n",
        "def update_pheromone(ants):\n",
        "    for i in range(num_items):\n",
        "        for j in range(max_weight+1):\n",
        "            pheromone[i][j] *= (1 - evaporation_rate)\n",
        "\n",
        "            sum = 0\n",
        "            lst = [ant['delta_pheromone'][i][j] for ant in ants]\n",
        "            for i in lst : \n",
        "              sum += i\n",
        "            total_weight = sum\n",
        "            \n",
        "            pheromone[i][j] += sum\n",
        "\n",
        "\n",
        "best_fitness = 0\n",
        "for iteration in range(100):\n",
        "    ants = []\n",
        "    total_fitness = 0\n",
        "    for ant_index in range(num_ants):\n",
        "        ant = {'solution': [0]*num_items, 'delta_pheromone': np.zeros((num_items, max_weight+1))}\n",
        "        remaining_weight = max_weight\n",
        "        while True:\n",
        "            item = item_selection(ant, remaining_weight)\n",
        "            if item is None:\n",
        "                break\n",
        "            ant['solution'][item] = 1\n",
        "            ant['delta_pheromone'][item][remaining_weight] += fitness(ant['solution'])\n",
        "            remaining_weight -= weights[item]\n",
        "        ant_fitness = fitness(ant['solution'])\n",
        "        total_fitness += ant_fitness\n",
        "        if ant_fitness > best_fitness:\n",
        "            best_fitness = ant_fitness\n",
        "            best_solution = ant['solution']\n",
        "        ants.append(ant)\n",
        "    update_pheromone(ants)\n",
        "    avg_fitness = total_fitness / num_ants\n",
        "    print(\"Iteration {}: Avg Fitness = {}\".format(iteration+1, avg_fitness))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GjaKHn-ZSbV",
        "outputId": "dc604c8f-24e5-4ca3-c0f2-9db79d32f1d1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Avg Fitness = 37.2\n",
            "Iteration 2: Avg Fitness = 36.3\n",
            "Iteration 3: Avg Fitness = 34.9\n",
            "Iteration 4: Avg Fitness = 37.9\n",
            "Iteration 5: Avg Fitness = 35.0\n",
            "Iteration 6: Avg Fitness = 36.6\n",
            "Iteration 7: Avg Fitness = 37.1\n",
            "Iteration 8: Avg Fitness = 32.0\n",
            "Iteration 9: Avg Fitness = 32.5\n",
            "Iteration 10: Avg Fitness = 36.1\n",
            "Iteration 11: Avg Fitness = 32.9\n",
            "Iteration 12: Avg Fitness = 37.7\n",
            "Iteration 13: Avg Fitness = 35.4\n",
            "Iteration 14: Avg Fitness = 35.8\n",
            "Iteration 15: Avg Fitness = 31.1\n",
            "Iteration 16: Avg Fitness = 36.3\n",
            "Iteration 17: Avg Fitness = 35.8\n",
            "Iteration 18: Avg Fitness = 37.1\n",
            "Iteration 19: Avg Fitness = 36.5\n",
            "Iteration 20: Avg Fitness = 34.4\n",
            "Iteration 21: Avg Fitness = 36.6\n",
            "Iteration 22: Avg Fitness = 33.3\n",
            "Iteration 23: Avg Fitness = 36.1\n",
            "Iteration 24: Avg Fitness = 38.1\n",
            "Iteration 25: Avg Fitness = 35.0\n",
            "Iteration 26: Avg Fitness = 36.1\n",
            "Iteration 27: Avg Fitness = 35.6\n",
            "Iteration 28: Avg Fitness = 34.6\n",
            "Iteration 29: Avg Fitness = 37.3\n",
            "Iteration 30: Avg Fitness = 37.5\n",
            "Iteration 31: Avg Fitness = 35.3\n",
            "Iteration 32: Avg Fitness = 33.4\n",
            "Iteration 33: Avg Fitness = 36.8\n",
            "Iteration 34: Avg Fitness = 35.2\n",
            "Iteration 35: Avg Fitness = 36.9\n",
            "Iteration 36: Avg Fitness = 38.6\n",
            "Iteration 37: Avg Fitness = 37.1\n",
            "Iteration 38: Avg Fitness = 38.1\n",
            "Iteration 39: Avg Fitness = 36.3\n",
            "Iteration 40: Avg Fitness = 31.2\n",
            "Iteration 41: Avg Fitness = 35.6\n",
            "Iteration 42: Avg Fitness = 34.9\n",
            "Iteration 43: Avg Fitness = 37.7\n",
            "Iteration 44: Avg Fitness = 34.8\n",
            "Iteration 45: Avg Fitness = 35.6\n",
            "Iteration 46: Avg Fitness = 33.8\n",
            "Iteration 47: Avg Fitness = 35.5\n",
            "Iteration 48: Avg Fitness = 35.3\n",
            "Iteration 49: Avg Fitness = 34.0\n",
            "Iteration 50: Avg Fitness = 36.1\n",
            "Iteration 51: Avg Fitness = 37.4\n",
            "Iteration 52: Avg Fitness = 35.9\n",
            "Iteration 53: Avg Fitness = 35.5\n",
            "Iteration 54: Avg Fitness = 38.1\n",
            "Iteration 55: Avg Fitness = 35.2\n",
            "Iteration 56: Avg Fitness = 35.3\n",
            "Iteration 57: Avg Fitness = 36.0\n",
            "Iteration 58: Avg Fitness = 38.0\n",
            "Iteration 59: Avg Fitness = 38.6\n",
            "Iteration 60: Avg Fitness = 37.6\n",
            "Iteration 61: Avg Fitness = 34.7\n",
            "Iteration 62: Avg Fitness = 35.8\n",
            "Iteration 63: Avg Fitness = 33.7\n",
            "Iteration 64: Avg Fitness = 36.4\n",
            "Iteration 65: Avg Fitness = 32.3\n",
            "Iteration 66: Avg Fitness = 33.0\n",
            "Iteration 67: Avg Fitness = 35.6\n",
            "Iteration 68: Avg Fitness = 35.6\n",
            "Iteration 69: Avg Fitness = 32.7\n",
            "Iteration 70: Avg Fitness = 36.4\n",
            "Iteration 71: Avg Fitness = 33.3\n",
            "Iteration 72: Avg Fitness = 35.5\n",
            "Iteration 73: Avg Fitness = 35.3\n",
            "Iteration 74: Avg Fitness = 32.8\n",
            "Iteration 75: Avg Fitness = 36.0\n",
            "Iteration 76: Avg Fitness = 37.9\n",
            "Iteration 77: Avg Fitness = 37.6\n",
            "Iteration 78: Avg Fitness = 36.7\n",
            "Iteration 79: Avg Fitness = 38.3\n",
            "Iteration 80: Avg Fitness = 37.9\n",
            "Iteration 81: Avg Fitness = 34.5\n",
            "Iteration 82: Avg Fitness = 32.2\n",
            "Iteration 83: Avg Fitness = 34.7\n",
            "Iteration 84: Avg Fitness = 36.4\n",
            "Iteration 85: Avg Fitness = 37.4\n",
            "Iteration 86: Avg Fitness = 37.5\n",
            "Iteration 87: Avg Fitness = 38.0\n",
            "Iteration 88: Avg Fitness = 36.0\n",
            "Iteration 89: Avg Fitness = 34.6\n",
            "Iteration 90: Avg Fitness = 37.3\n",
            "Iteration 91: Avg Fitness = 33.3\n",
            "Iteration 92: Avg Fitness = 35.3\n",
            "Iteration 93: Avg Fitness = 37.7\n",
            "Iteration 94: Avg Fitness = 33.5\n",
            "Iteration 95: Avg Fitness = 37.6\n",
            "Iteration 96: Avg Fitness = 34.2\n",
            "Iteration 97: Avg Fitness = 37.9\n",
            "Iteration 98: Avg Fitness = 31.5\n",
            "Iteration 99: Avg Fitness = 38.2\n",
            "Iteration 100: Avg Fitness = 38.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "input_size = 20\n",
        "hidden_size = 10\n",
        "output_size = 1\n",
        "\n",
        "weights_1 = []\n",
        "for name, param in net.named_parameters():\n",
        "    if 'weight' in name:\n",
        "        weights_1.append(param.data.tolist())\n",
        "\n",
        "weights = []\n",
        "sum = 0\n",
        "for i in weights_1 :\n",
        "  for j in i :\n",
        "    for k in j :\n",
        "      sum += k\n",
        "    weights.append(sum)\n",
        "\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-nzKDqPmrHZ",
        "outputId": "599b6b73-9066-4851-c746-24e5cd3e5672"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11.358983531594276,\n",
              " 22.199279807507992,\n",
              " 34.72416888922453,\n",
              " 46.6854255720973,\n",
              " 57.15083331614733,\n",
              " 67.87197101861238,\n",
              " 79.21215907484293,\n",
              " 88.99147949367762,\n",
              " 98.39448668807745,\n",
              " 108.43941444903612,\n",
              " 113.16909411083907]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    }
  ]
}